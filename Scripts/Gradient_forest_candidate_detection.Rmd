---
title: "Gradient_forest_candidate_detection"
author: "Thomas Francisco"
date: "2024-04-30"
output:
  html_document:
    number_sections: true #titles
    toc: true #table of content
    toc_float: true # enable the toc to be on the side of the text, always visible
    collapsed: True #control if the toc label will only display top level titles
    toc_depth: 3
---

# Introduction

This script performs candidate detection using **Gradient Forest (GF).**
Gradient Forest is a machine learning method introduced by Ellis, Smith, and Pitcher (2012). Fitzpatrick & Keller (2015) describe how GF can be used to:  
- Analyse and map spatial variation in allele frequencies as a function of environmental gradients (outlier detection via GEA).  
- Project patterns of genomic variation under different climates (genomic offset).  

More specifically, GF uses Random Forest to fit an ensemble of regression trees modeling changes in allele frequencies across sites and derives monotonic, nonlinear functions of environmental predictors. The empirical, nonlinear turnover functions are constructed by distributing the R² values of all SNPs across predictor gradients in proportion to their importance and along each gradient according to the density of the raw split importance values. The split importance values for all modeled SNPs are aggregated into an overall genome-wide turnover function for each variable, weighted by predictor importance and goodness-of-fit for each SNP model (Fitzpatrick et al., 2021).

GF is considered univariate/multivariate because it models one response variable and one predictor at a time but then summarizes information into cumulative importance turnover functions. This allows results for multiple climate variables simultaneously for a single SNP. GF can also apply the same process across response variables to summarize the effect of explanatory variables on multiple responses (Ellis et al., 2012).

(For comparison: RDA is multivariate, analysing multiple response variables simultaneously. LFMM can be univariate or multivariate depending on the configuration, and BAYPASS is univariate.)

In this script, we apply the GF algorithm for outlier detection following Fitzpatrick et al. (2021) and Archambeau et al. GF will be run on genomic datasets both corrected and uncorrected for population structure. GF will be performed for each SNP, producing a turnover function per SNP using all predictors.

To assess the association of each locus with climatic variables, we calculated empirical p-values. These p-values are derived by comparing a null distribution of R² values with the R² value of each locus: the farther a locus R² is from the null distribution, the lower its p-value.

The first step in this process is selecting the set of SNPs used to generate the null distribution. If available, SNPs from intergenic or non-coding regions identified via genetic load are preferred. In this study, such SNPs are not available; thus, following Archambeau et al. (2024), we use a random subset of SNPs from the dataset to generate the null distribution.

To ensure robustness, we run the model 5 times for each dataset. Candidate SNPs for each dataset are defined as those that overlap across all 5 runs, as SNPs identified in a single run may vary slightly (Archambeau et al., 2024).

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(cache = FALSE)
#download gradientforest package
#install.packages("gradientForest", repos=c("http://R-Forge.R-project.org",
#"http://cran.at.r-project.org"),dependencies=TRUE)
library(gradientForest)
library(dplyr)
library(tidyr)
library(writexl)
library(VennDiagram)
library(radiant.data) #for row_names_to_columns
library(textshape) #for colnames_to_row.names
```

## Formatting the genomic and the climatic data

To perform the Gradient Forest analysis following Fitzpatrick et al. (2021), the data must be formatted with populations in rows and SNPs in columns. It is crucial that the order of populations is consistent between the genomic and climate data files.

### Climatic data
```{r climatic_data}
#climatic data
Past_climatic <- read.csv("C:/Users/tfrancisco/Documents/Thesis/Data/Species/Taxus_baccata/Climatic_data/new_selection/Past_new_6_Climatic_data_scale_df.csv",sep=";",dec=",")
vars <- colnames(Past_climatic[,-c(1:2)])
```

### Genomic data 

#### GF raw

The genomic file used is filtered with a minimum allele frequency (MAF) cut-off of 0.20, as low-frequency alleles could potentially bias the genomic–environmental association (GEA) analyses. The same MAF threshold was applied consistently across all GEA methods.
```{r formatting data}
#genomic data
load("C:/Users/tfrancisco/Documents/Thesis/Data/Species/Taxus_baccata/genetic_new/data_allelic_frequencies_29pop_adapcon_gentree_475_8616.Rdata")

genomic_matrix <- data_allelic_frequencies_29pop_adapcon_gentree_475_8616
```

#### GF corrected
Gradient Forest (GF) does not have an option to directly correct for population structure. To account for population structure in GF, we must use a genomic dataset that has already been corrected. The scaled population structure matrix from BAYPASS cannot be used, as GF requires a data frame rather than a matrix. Instead, we can use the genotypic dataset corrected for population structure via latent factors in LFMM.  

We load the corrected LFMM genomic dataframe. The genomic data is at the individual level for 475 individuals, 8616 imputed SNPs and with MAF correction.
```{r load genotypic dataset corrected for populations structure}
load("C:/Users/tfrancisco/Documents/Thesis/Data/Species/Taxus_baccata/genetic_new/GEA/Genomic_matrix_corrected_from_LFMM_T_adapcon_gentree.Rdata")
corrected_geno_data <- Genomic_matrix_corrected_from_LFMM_T_adapcon_gentree
#we need to transform the individual dataframe into a population-level dataframe

#add ind into a column
corrected_geno_data_ind <- rownames_to_column(corrected_geno_data, "VCF_ID")
```

We need to transform the genomic data at the individual level to the population level: 
```{r geno indiv-level to population-level, message=FALSE, warning=FALSE}
#add the population info
#meta_data
meta_data_pop <- read.csv("C:/Users/tfrancisco/Documents/Thesis/Data/Species/Taxus_baccata/Populations/taxus_sample_29pop.csv",h=T,sep=";",dec=",")

meta_data_vcf <- read.csv("C:/Users/tfrancisco/Documents/Thesis/Data/Species/Taxus_baccata/Samples/samples_taxus_baccata_adapcon_gentree.csv",h=T,sep=";",dec=",")

geno_pop_info <- merge(meta_data_vcf,corrected_geno_data_ind, "VCF_ID" )

#formatting the genomic data
data_frequencies_num <- geno_pop_info[,-c(1:3)] %>% #keeping only the snps
  apply(2,as.numeric) /2 #we divided by 2 because of the format of genomic data: 0,1,2 and for allelic frequencies and we want 0,0.5, 1

#dataset with all information and genomic data in the right format
data_frequencies_num_tot <- data.frame(geno_pop_info[,c(1:3)],data_frequencies_num)

#calculation of allelic frequencies
allelic_frequencies <-data_frequencies_num_tot %>% dplyr::select(-c("VCF_ID","Country","Population")) %>% #remove non genomic data from the dataset
  group_by(data_frequencies_num_tot$Population) %>% #we want the allelic frequencies at the population level so we grouped
  summarise_at(vars(everything()),funs(mean),na.rm=T) %>% #calculate the mean for each snp per pop
    ungroup() %>%
as.data.frame()

#Pop with row.names
allelic_frequencies_f <- allelic_frequencies %>% column_to_rownames('data_frequencies_num_tot$Population')
```

# Run the models
    
In this step, we will run the GF algorithm five times because, due to the stochastic nature of the machine learning process, the set of candidate SNPs may vary between runs. Additionally, the random selection of SNPs to generate the null distribution can lead to different candidates being identified in each run. To ensure robustness, we will only consider SNPs that are consistently identified as candidates across all five runs. This approach ensures that the selected candidates reflect true signals rather than random variation.

```{r function to perform the GF and output the results in 1 code, message=FALSE, warning=FALSE}
Run_GF_and_select_outliers <- function(genomic_matrix, climatic_data, ntree, cores,nbr_loci_distrib,vars,x,path){
  #GF function
  runGF <- function(alFreq,  envTab, vars, ntree, 
                  cores, indLoci){
  require(data.table)
  require(gradientForest)
  require(parallel)
  require(foreach)
  require(doParallel)
  library(doParallel)
  library(foreach)
  library(parallel)
  library(gradientForest)
  library(data.table)
  
  if(identical(envTab$Population,rownames(alFreq))==F){
    stop("Populations are not in the same order in the genomic and climatic tables.")
  }
  
  # create custom object to hold output 
  gfOutObj <- setClass("gfOutObj", slots = c(alFreq="data.frame", imp="list"))

  # run in parallel if fitting SNPs individually
  if(indLoci==T & !is.na(cores)){
    # fit gf model to each SNP individually
    cl <- makeCluster(cores, setup_strategy = "sequential")
    registerDoParallel(cl)

    gfMods <- foreach(k=1:ncol(alFreq), .verbose=F, .packages=c("gradientForest"), .errorhandling = c("pass")) %dopar%{
      locus <- data.frame(alFreq[,k])
      names(locus) <- colnames(alFreq)[k]
      gf.mod <- gradientForest(data.frame(envTab[, vars], locus), 
                               predictor.vars=vars, response.vars=colnames(alFreq)[k], 
                               corr.threshold=0.5, ntree=ntree, trace=T)
    if(!is.null(gf.mod)){
        imps <- importance(gf.mod)
        imps <- imps[order(names(imps))]
        data.frame(imps, SNP = colnames(alFreq)[k])
      }
    }
    
    stopCluster(cl)
    return(gfOutObj(alFreq = data.frame(alFreq), imp = gfMods))
  } else {
    # run all SNPs at once if not fitting individually
    gf.mod <- gradientForest(data.frame(envTab[, vars], alFreq), 
                             predictor.vars=vars, response.vars=colnames(alFreq), 
                             corr.threshold=0.5, ntree=ntree, trace=T)
    
    return(gfOutObj(alFreq = data.frame(alFreq), imp = gfMods))
  }
}
  #run GF
  GF_test <- runGF(genomic_matrix,climatic_data,vars,ntree=ntree, 
                  cores=cores, indLoci=T)
  
  #extract the loci correlated to the climate
  Extract_correlation_loci_climate<- GF_test@imp
loci_correlated_climate <- Filter(function(x) !inherits(x, "error"),  Extract_correlation_loci_climate)

#extracting R^2 values
gfR2tab <- function(gfMods.list){
  gfMods.list <- gfMods.list
  i=1
  while(is.null(gfMods.list[[i]])){i=i+1}
  tab <- do.call(rbind, gfMods.list)
  vrNm <- rep(row.names(tab)[1:nrow(gfMods.list[[i]])], 
              nrow(tab)/nrow(gfMods.list[[i]]))
  tab <- data.frame(variable=vrNm, tab)
  tab <- reshape2::dcast(tab, SNP~variable, value.var="imps")
  totalR2 <- rowSums(tab[,-1])
  return(data.frame(tab, totalR2=totalR2))}

dataset_R2_loci_climate <- gfR2tab(loci_correlated_climate)

  #select randomly the SNPs, we selected 20% of all SNPs to create the null distribution
name_neutral_snps <- sample(dataset_R2_loci_climate$SNP,nbr_loci_distrib,replace = F)

neutral_snps_set <- dataset_R2_loci_climate %>% 
    filter(SNP %in% name_neutral_snps)

#hist neutral 
 neutral_R2_distrib<-hist(neutral_snps_set$totalR2)
 
 #name
neutral_R2_distrib<-hist(neutral_snps_set$totalR2)

#save the histogram
 png(filename=paste0(path,x,"neutral_R2_distrib",".png"))
 
# a histogram we want to save
hist(neutral_snps_set$totalR2)
# call this function to save the file 
dev.off()
 
#empirical pvalues
empirical_pvalues <- sapply(1:nrow(dataset_R2_loci_climate), function(x, dataset_R2_loci_climate, name_neutral_snps, neutral_snps_set){
    snps2Rank <- rbind(dataset_R2_loci_climate[x,], neutral_snps_set) %>% 
      distinct() %>% 
      dplyr::select(-SNP)
    P <- apply(snps2Rank, 2, function(y){
      rankSNP <- frank(y)
      return(1-rankSNP[1]/length(rankSNP))
    })}, dataset_R2_loci_climate, neutral_snps, neutral_snps_set)
  

  # format output as data.frame
  empirical_pvalues_df <- t(empirical_pvalues)
  colnames(empirical_pvalues_df) <- paste("pval_", colnames(empirical_pvalues_df), sep="")
  empirical_pvalues_df <- data.frame(dataset_R2_loci_climate, empirical_pvalues_df)

    #visualise the pvalues distribution
  pvalues_distribution <- hist(empirical_pvalues_df$pval_totalR2)
  
  
  #save the histogram
png(filename=paste0(path,"pvalues_distribution",x,".png"))

# a histogram we want to save
hist(empirical_pvalues_df$pval_totalR2)

# call this function to save the file 
dev.off()
  # Return the pvalues 
  return(empirical_pvalues_df)
}
```

```{r run the models,eval=FALSE,echo=FALSE}
GF_data <- c("genomic_matrix","allelic_frequencies_f")
GF_models <- c("GF_raw","GF_corrected")
for(i in 1: length(GF_data)){
  
  genomic_data <- get(GF_data[i])
  model_name <- GF_models[i]
  path <- paste0("C:/Users/tfrancisco/Documents/Thesis/Data/Species/Taxus_baccata/GEA_new_var/Gradient_forest/",model_name,"/")
  
for(x in 1:5){
  name_file <- paste0("Run_",x,"_",model_name)
  Run <- Run_GF_and_select_outliers(genomic_matrix, Past_climatic, 500, 4,600,vars,x=x,path)
  assign(name_file, Run)
  
  #We save the Runs of GF_raw if needed to rerun them to change threshold or perform new analysis/ figures
  #save(paste0("Run_",x,"_",model_name),file=paste0("C:/Users/tfrancisco/Documents/Thesis/Data/Species/Taxus_baccata/GEA_new_var/Gradient_forest/",model_name,"/","Run",x,".Rdata"))
  }
}
```

We can load the run to skip the previous steps. 
```{r load RUNs, include=FALSE}
GF_data <- c("genomic_matrix","allelic_frequencies_f")
GF_models <- c("GF_raw","GF_corrected")

for(i in 1: length(GF_models)){
  model_name <- GF_models[i]
for(x in 1:5){
  load(paste0("C:/Users/tfrancisco/Documents/Thesis/Data/Species/Taxus_baccata/GEA_new_var/Gradient_forest/",model_name,"/","Run",x,".Rdata"))
  assign(paste0("Run",x,"_",model_name),get(paste0("Run",x)))
  }
}
```
  
# Identification of candidate loci

## Thresholds

Now we want to identify candidate SNPs. To do that, we applied 2 types of thresholds:   
**rank pvalues threshold:**  
- rank based 5%  
- rank based 1%  
        
**pvalues threshold:**  
- pvalues 0.05  
- pvalues 0.01  
    
```{r calculation of thresholds}
for(i in 1: length(GF_data)){
  genomic_data <- get(GF_data[i])
  model_name <- GF_models[i]

for(x in 1:5){
  data_name <- paste0("Run",x,"_",model_name)
  
  data <- get(data_name)
  
   #top 1%
  
 outliers_top1perc_GF <- data[,c(1,15)] %>% 
  arrange(pval_totalR2) %>%
slice(1:(0.01*8616)) %>%  #slice(1:(0.01*nrow(.)))
  as.data.frame()
 
 assign(paste0("Run",x,"_",model_name,"_top1SNP"),outliers_top1perc_GF)
 
   #top 5%
 outliers_top5perc_GF <- data[,c(1,15)] %>% 
  arrange(pval_totalR2) %>%
slice(1:(0.05*nrow(data))) %>%  #slice(1:(0.01*nrow(.)))
  as.data.frame()
 
 assign(paste0("Run",x,"_",model_name,"_top5SNP"),outliers_top5perc_GF)
 
 #pvalues < 0.05
outliers_pv05 <- data[,c(1,15)] %>% filter(pval_totalR2<0.05) %>% pull(SNP) 

 assign(paste0("Run",x,"_",model_name,"_outliers_pv0.05"),outliers_pv05)

#pvalues < 0.01
outliers_pv0.01 <- data[,c(1,15)] %>% filter(pval_totalR2<0.01) %>% pull(SNP)
 
 assign(paste0("Run",x,"_",model_name,"_outliers_pv0.01"),outliers_pv0.01)
  }
}
```


## Graphical visualisation

An important step is to compare the results across different runs for each threshold. We created Venn diagrams to visualize the number of candidate SNPs shared between runs.
```{r plot venn_diagram for comparison across runs}
for(i in 1: length(GF_data)){
  genomic_data <- get(GF_data[i])
  model_name <- GF_models[i]

#candidates 0.01
grid.newpage()
ven <- venn.diagram(
  x = list(
    get(paste0("Run1_",model_name,"_outliers_pv0.01")), 
    get(paste0("Run2_",model_name,"_outliers_pv0.01")), 
    get(paste0("Run3_",model_name,"_outliers_pv0.01")), 
    get(paste0("Run4_",model_name,"_outliers_pv0.01")), 
    get(paste0("Run5_",model_name,"_outliers_pv0.01"))
  ),
  category.names = c("RUN1", "RUN2", "RUN3", "RUN4", "RUN5"),
  filename = NULL,
  fill = c("#E69F00", "#56B4E9", "#009E73", "#D55E00","#CC79A7"),
  alpha = 0.30,
  print.mode = c("raw","percent"),  # Display raw counts + percentages
  sigdigs = 0,  # Round percentages to whole numbers
  margin = 0.1,  # Adjust margins
  cat.fontface = "italic",  # Italic category labels
  cat.fontsize = 14,  # Increase category label size
  main = paste0("Venn Diagram: pv 0.01 candidate SNPs across ",model_name," Runs"),
  main.fontface = "bold",
  main.cex = 1.5,  # Increase main title size
  cex = 1.5  # Increase text size inside the Venn diagram
)
grid.draw(ven)

#top 1%
grid.newpage()
ven <- venn.diagram(
  x = list(
    get(paste0("Run1_", model_name, "_top1SNP"))[, 1], 
    get(paste0("Run2_", model_name, "_top1SNP"))[, 1], 
    get(paste0("Run3_", model_name, "_top1SNP"))[, 1], 
    get(paste0("Run4_", model_name, "_top1SNP"))[, 1], 
    get(paste0("Run5_", model_name, "_top1SNP"))[, 1]
  ),
  category.names = c("RUN1", "RUN2", "RUN3", "RUN4", "RUN5"),
  filename = NULL,
  fill = c("#E69F00", "#56B4E9", "#009E73", "#D55E00","#CC79A7"),
  alpha = 0.30,
  print.mode = c("raw","percent"),  # Display raw counts + percentages
  sigdigs = 0,  # Round percentages to whole numbers
  margin = 0.1,  # Adjust margins
  cat.fontface = "italic",  # Italic category labels
  cat.fontsize = 14,  # Increase category label size
  main = paste0("Venn Diagram: Top 1% Candidate SNPs Across ",model_name," Runs"),
  main.fontface = "bold",
  main.cex = 1.5,  # Increase main title size
  cex = 1.5  # Increase text size inside the Venn diagram
)
grid.draw(ven)

#top 5% 
grid.newpage()
ven <- venn.diagram(
  x = list(
    get(paste0("Run1_", model_name, "_top5SNP"))[, 1], 
    get(paste0("Run2_", model_name, "_top5SNP"))[, 1], 
    get(paste0("Run3_", model_name, "_top5SNP"))[, 1], 
    get(paste0("Run4_", model_name, "_top5SNP"))[, 1], 
    get(paste0("Run5_", model_name, "_top5SNP"))[, 1]
  ),
  category.names = c("RUN1", "RUN2", "RUN3", "RUN4", "RUN5"),
  filename = NULL,
  fill = c("#E69F00", "#56B4E9", "#009E73", "#D55E00","#CC79A7"),
  alpha = 0.30,
  print.mode = c("raw","percent"),  # Display raw counts + percentages
  sigdigs = 0,  # Round percentages to whole numbers
  margin = 0.1,  # Adjust margins
  cat.fontface = "italic",  # Italic category labels
  cat.fontsize = 14,  # Increase category label size
  main = paste0("Venn Diagram: Top 5% Candidate SNPs Across ",model_name," Runs"),
  main.fontface = "bold",
  main.cex = 1.5,  # Increase main title size
  cex = 1.5  # Increase text size inside the Venn diagram
)

# Draw the Venn diagram
grid.draw(ven)
}
```

```{r save venn_diagram plots, message=FALSE, warning=FALSE, include=FALSE}
for(i in 1: length(GF_data)){

  genomic_data <- get(GF_data[i])
  model_name <- GF_models[i]
  #candidates 0.01
venn.diagram(x = list(get(paste0("Run1_",model_name,"_outliers_pv0.01")), get(paste0("Run2_",model_name,"_outliers_pv0.01")), get(paste0("Run3_",model_name,"_outliers_pv0.01")), get(paste0("Run4_",model_name,"_outliers_pv0.01")), get(paste0("Run5_",model_name,"_outliers_pv0.01"))),
        category.names = c("RUN1" , "RUN2 ","RUN3","RUN4","RUN5"),
        filename = paste0("C:/Users/tfrancisco/Documents/Thesis/Results/species/taxus/GEA_new_var/Gradient_forest/",model_name,"/venn_diagramm_GF_raw_pv0.01.png"),fill = c("#E69F00", "#56B4E9", "#009E73", "#D55E00","#CC79A7"),
alpha = 0.30,
print.mode=c("raw"),
imagetype="png",
output=TRUE,
margin = 0.1,  # Adjust the margins
                    cat.fontface = "italic",  # Optional: Make category names italic
                    cat.fontsize = 14,
                    main= paste0("Venn Diagram: pv 0.01 candidate SNPs across ",model_name," Runs"),
                    main.fontface = "bold",
                    main.cex = 1.5,  # Increase main title size
                    cex = 1.5)  # Increase text size inside the Venn diagram

  #candidates 0.05
venn.diagram(x = list(get(paste0("Run1_",model_name,"_outliers_pv0.05")), get(paste0("Run2_",model_name,"_outliers_pv0.05")), get(paste0("Run3_",model_name,"_outliers_pv0.05")), get(paste0("Run4_",model_name,"_outliers_pv0.05")), get(paste0("Run5_",model_name,"_outliers_pv0.05"))),
        category.names = c("RUN1" , "RUN2 ","RUN3","RUN4","RUN5"),
        filename = paste0("C:/Users/tfrancisco/Documents/Thesis/Results/species/taxus/GEA_new_var/Gradient_forest/",model_name,"/venn_diagramm_GF_raw_pv0.05.png"),fill = c("#E69F00", "#56B4E9", "#009E73", "#D55E00","#CC79A7"),
alpha = 0.30,
print.mode=c("raw"),
imagetype="png",
output=TRUE,
margin = 0.1,  # Adjust the margins
                    cat.fontface = "italic",  # Optional: Make category names italic
                    cat.fontsize = 14,
                    main= paste0("Venn Diagram: pv 0.05 candidate SNPs across ",model_name," Runs"),
                    main.fontface = "bold",
                    main.cex = 1.5,  # Increase main title size
                    cex = 1.5)  # Increase text size inside the Venn diagram


 #top 1%
venn.diagram(x = list(get(paste0("Run1_",model_name,"_top1SNP"))[,1], get(paste0("Run2_",model_name,"_top1SNP"))[,1], get(paste0("Run3_",model_name,"_top1SNP"))[,1], get(paste0("Run4_",model_name,"_top1SNP"))[,1], get(paste0("Run5_",model_name,"_top1SNP"))[,1]),
        category.names = c("RUN1" , "RUN2 ","RUN3","RUN4","RUN5"),
        filename = paste0("C:/Users/tfrancisco/Documents/Thesis/Results/species/taxus/GEA_new_var/Gradient_forest/",model_name,"/venn_diagramm_GF_raw_top1.png"),fill = c("#E69F00", "#56B4E9", "#009E73", "#D55E00","#CC79A7"),
alpha = 0.30,
print.mode=c("raw"),
imagetype="png",
output=TRUE,
margin = 0.1,  # Adjust the margins
                    cat.fontface = "italic",  # Optional: Make category names italic
                    cat.fontsize = 14,
                    main= paste0("Venn Diagram: Top 1% Candidate SNPs Across ",model_name," Runs"),
                    main.fontface = "bold",
                    main.cex = 1.5,  # Increase main title size
                    cex = 1.5)  # Increase text size inside the Venn diagram

 #top 5%
venn.diagram(x = list(get(paste0("Run1_",model_name,"_top5SNP"))[,1], get(paste0("Run2_",model_name,"_top5SNP"))[,1], get(paste0("Run3_",model_name,"_top5SNP"))[,1], get(paste0("Run4_",model_name,"_top5SNP"))[,1], get(paste0("Run5_",model_name,"_top5SNP"))[,1]),
        category.names = c("RUN1" , "RUN2 ","RUN3","RUN4","RUN5"),
        filename = paste0("C:/Users/tfrancisco/Documents/Thesis/Results/species/taxus/GEA_new_var/Gradient_forest/",model_name,"/venn_diagramm_GF_raw_top5.png"),fill = c("#E69F00", "#56B4E9", "#009E73", "#D55E00","#CC79A7"),
alpha = 0.30,
print.mode=c("raw"),
imagetype="png",
output=TRUE,
margin = 0.1,  # Adjust the margins
                    cat.fontface = "italic",  # Optional: Make category names italic
                    cat.fontsize = 14,
                    main= paste0("Venn Diagram: Top 5% Candidate SNPs Across ",model_name," Runs"),
                    main.fontface = "bold",
                    main.cex = 1.5,  # Increase main title size
                    cex = 1.5)  # Increase text size inside the Venn diagram


}
```

Overall, we observe that only a subset of SNPs identified as candidates is consistently shared across runs. Furthermore, the top-candidate approach appears more robust than using empirical p-values, which show greater variability and less consistency across runs. This suggests that relying on top candidates is a more appropriate method for identifying robust signals.

# Save candidates
As candidates, we selected and saved the top candidates:

## 1% of SNPs for downstream analysis
```{r select the overlapping candidates across runs and save them 1%}
for(i in 1: length(GF_data)){

  genomic_data <- get(GF_data[i])
  model_name <- GF_models[i]

#Select only the candidates identified in all 5 runs
outliers_rank_based_top1perc <- Reduce(intersect, list(get(paste0("Run1_",model_name,"_top1SNP"))[,1], get(paste0("Run2_",model_name,"_top1SNP"))[,1], get(paste0("Run3_",model_name,"_top1SNP"))[,1], get(paste0("Run4_",model_name,"_top1SNP"))[,1], get(paste0("Run5_",model_name,"_top1SNP"))[,1]))

#number of outliers
length(outliers_rank_based_top1perc)

assign(paste0("outliers_rank_based_top1perc_",model_name),outliers_rank_based_top1perc)
#save
   save(list = paste0("outliers_rank_based_top1perc_",model_name), file = paste0("C:/Users/tfrancisco/Documents/Thesis/Results/species/taxus/GEA_new_var/outliers/outliers_rank_based_top1perc_", model_name, ".Rdata"))
}
```

## 5% of SNPs for downstream analysis as a relax threshold candidates
```{r select the overlapping candidates across runs and save them 5%}
for(i in 1: length(GF_data)){

  genomic_data <- get(GF_data[i])
  model_name <- GF_models[i]
  
#Select only the outliers identified in all 5 runs
outliers_rank_based_top5perc <- Reduce(intersect, list(get(paste0("Run1_",model_name,"_top5SNP"))[,1], get(paste0("Run2_",model_name,"_top5SNP"))[,1], get(paste0("Run3_",model_name,"_top5SNP"))[,1], get(paste0("Run4_",model_name,"_top5SNP"))[,1], get(paste0("Run5_",model_name,"_top5SNP"))[,1]))

#number of outliers
length(outliers_rank_based_top5perc)

assign(paste0("outliers_rank_based_top5perc_",model_name),outliers_rank_based_top5perc)

#save
   save(list = paste0("outliers_rank_based_top5perc_",model_name), file = paste0("C:/Users/tfrancisco/Documents/Thesis/Results/species/taxus/GEA_new_var/outliers/outliers_rank_based_top5perc_", model_name, ".Rdata"))
}
```